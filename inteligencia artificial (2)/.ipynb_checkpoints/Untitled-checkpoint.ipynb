{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8be584f-c4d5-4b48-a9ae-157b751490c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import vlc\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Configuración de la cámara\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 2560)\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1440)\n",
    "\n",
    "# Cargamos los clasificadores de OpenCV para detectar ojos\n",
    "eyeLeft = cv2.CascadeClassifier('/Users/Juniot/anaconda3/envs/nombre/Lib/site-packages/cv2/data/haarcascade_lefteye_2splits.xml')  # modelo ojo izquierdo\n",
    "eyeRight = cv2.CascadeClassifier('/Users/Juniot/anaconda3/envs/nombre/Lib/site-packages/cv2/data/haarcascade_righteye_2splits.xml')  # modelo ojo derecho\n",
    "\n",
    "# Inicialización del modelo Keras\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)  # inicializar la variable data\n",
    "model = load_model('keras_model.h5')  # cargar el modelo\n",
    "\n",
    "# Configuración del reproductor VLC\n",
    "p = vlc.MediaPlayer(\"Mejores Sonidos FUERTES para ALARMA Te despiertas SI o SI  tonos para despertador  tonos de alarma.mp3\")\n",
    "\n",
    "# Inicialización de las coordenadas de los ojos\n",
    "left_x, left_y, left_w, left_h = 0, 0, 0, 0  # coordenadas ojo izquierdo\n",
    "right_x, right_y, right_w, right_h = 0, 0, 0, 0  # coordenadas ojo derecho\n",
    "contador = 0  # contador para seguimiento de dormido/despierto\n",
    "\n",
    "# Bucle principal de captura de video\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    height, width = frame.shape[:2]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convertir imagen a escala de grises\n",
    "\n",
    "    # Mostrar el contador en pantalla\n",
    "    cv2.rectangle(frame, (0, 0), (width, int(height*0.1)), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, '             ' + str(contador), (int(width*0.65), int(height*0.08)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "\n",
    "    # Detección del ojo derecho\n",
    "    ojo_der = eyeRight.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.15,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    for (x, y, w, h) in ojo_der:  # recorrer las detecciones del ojo derecho\n",
    "        right_x, right_y, right_w, right_h = x, y, w, h\n",
    "        break  # tomar solo la primera detección\n",
    "\n",
    "    # Detección del ojo izquierdo\n",
    "    ojo_izq = eyeLeft.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.15,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    for (x, y, w, h) in ojo_izq:  # recorrer las detecciones del ojo izquierdo\n",
    "        left_x, left_y, left_w, left_h = x, y, w, h\n",
    "        break\n",
    "\n",
    "    # Definir las coordenadas para extraer los ojos\n",
    "    if left_x > right_x:\n",
    "        start_x, end_x = right_x, (left_x + left_w)\n",
    "    else:\n",
    "        start_x, end_x = left_x, (right_x + right_w)\n",
    "\n",
    "    if left_y > right_y:\n",
    "        start_y, end_y = right_y, (left_y + left_h)\n",
    "    else:\n",
    "        start_y, end_y = left_y, (right_y + right_h)\n",
    "\n",
    "    # Comprobación de las dimensiones de la imagen de los ojos\n",
    "    if (end_x - start_x) > 120 and (end_y - start_y) < 200:\n",
    "        start_x, start_y, end_x, end_y = start_x - 30, start_y - 50, end_x + 30, end_y + 50\n",
    "        cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "\n",
    "        # Extraer y preparar la imagen para el modelo\n",
    "        img = frame[start_y:end_y, start_x:end_x]\n",
    "        imagen = cv2.resize(img, (224, 224))\n",
    "        imagen_normalizada = (imagen.astype(np.float32) / 127.0) - 1\n",
    "        data[0] = imagen_normalizada\n",
    "\n",
    "        # Hacer predicción con el modelo\n",
    "        prediction = model.predict(data)\n",
    "\n",
    "        # Si la probabilidad de dormido es alta\n",
    "        if list(prediction)[0][1] >= 0.95:\n",
    "            cv2.putText(frame, 'Dormido: ' + 'probabilidad: ' + str(round(list(prediction)[0][1], 3)), (10, int(height*0.08)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "            contador += 1\n",
    "\n",
    "        # Si la probabilidad de despierto es alta\n",
    "        if list(prediction)[0][0] >= 0.95:\n",
    "            cv2.putText(frame, 'Despierto', (10, int(height*0.08)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "            contador -= 1\n",
    "\n",
    "        # Control del contador y reproducción del sonido de alarma\n",
    "        if contador >= 15:\n",
    "            contador = 15\n",
    "            p.play()  # reproducir alarma si está dormido\n",
    "        elif 0 < contador < 15:\n",
    "            p.stop()  # detener alarma si se despierta\n",
    "        elif contador < 0:\n",
    "            contador = 0\n",
    "\n",
    "    # Mostrar el video de la webcam\n",
    "    cv2.imshow('video', frame)\n",
    "\n",
    "     #Tecla de salida - acaba la transmisión\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83d752-849e-4426-b426-839be6466245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85800dc6-0309-4b6a-8127-211c51a6f16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
